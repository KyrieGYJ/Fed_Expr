{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ubuntu/Fed_Expr', '/home/ubuntu/Fed_Expr/FedML', '/home/ubuntu/Fed_Expr/MyExpr', '/home/ubuntu/Fed_Expr/MyExpr/dfl', '/home/ubuntu/miniconda/envs/fedml/lib/python37.zip', '/home/ubuntu/miniconda/envs/fedml/lib/python3.7', '/home/ubuntu/miniconda/envs/fedml/lib/python3.7/lib-dynload', '', '/home/ubuntu/miniconda/envs/fedml/lib/python3.7/site-packages', '/home/ubuntu/miniconda/envs/fedml/lib/python3.7/site-packages/IPython/extensions', '/home/ubuntu/.ipython']\n"
     ]
    }
   ],
   "source": [
    "# 失败的实验，因为KL散度要计算softmax，但是二分类只输出一个值，懒得再去改数据了，直接去做实验得了。\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# 添加环境\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../MyExpr\")))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../FedML\")))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f272475adf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "# todo 拉配置\n",
    "parser = argparse.ArgumentParser(\"cifar\")\n",
    "parser.add_argument('--data_name', type=str, default=\"SUSY\", help='SUSY; RO')\n",
    "parser.add_argument('--epoch_size', type=int, default=10, help='1,2,3,4,5')\n",
    "# parser.add_argument('--learning_rate', type=float, default=0.1)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=100)\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0001)\n",
    "parser.add_argument('--beta', type=float, default=0.2, help='beta: 0; 0.2; 0.5')\n",
    "parser.add_argument('--client_number', type=int, default=100, help='client number')\n",
    "parser.add_argument('--b_symmetric', type=int, default=0)\n",
    "parser.add_argument('--topology_neighbors_num_undirected', type=int, default=4)\n",
    "parser.add_argument('--topology_neighbors_num_directed', type=int, default=4)\n",
    "parser.add_argument('--input_dim', type=int, default=18)\n",
    "parser.add_argument('--output_dim', type=int, default=1)\n",
    "parser.add_argument('--learning_rate', type=float, default=0.01)\n",
    "parser.add_argument('--latency', type=float, default=0)\n",
    "\n",
    "# parser.parse_args()\n",
    "args = parser.parse_known_args()[0]\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# args.__setattr__(\"epoch_size\", 100)\n",
    "# print(args.epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载全部数据...完成\n",
      "加载对抗数据...完成\n",
      "加载随机数据...完成\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "from MyExpr.dfl.data_loader_for_susy_dfl import DataLoader\n",
    "\n",
    "client_number = args.client_number\n",
    "client_id_list = [i for i in range(client_number)]\n",
    "beta = args.beta\n",
    "\n",
    "reload = False\n",
    "# 总共 4500000\n",
    "train_sample_num_in_total = 450000\n",
    "# todo 测试数据是否划分正确\n",
    "if reload:\n",
    "    dataloader = DataLoader(\"SUSY\", \"../../FedML/data/UCI/SUSY/SUSY.csv\", client_id_list, train_sample_num_in_total, beta)\n",
    "    batch_data_dict = dataloader.load_data()\n",
    "    test_X, test_Y = dataloader.test_X, dataloader.test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# LR model\n",
    "import torch\n",
    "\n",
    "# logistic\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "finished topology generation\n",
      "finished client generation\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from FedML.fedml_api.standalone.decentralized.topology_manager import TopologyManager\n",
    "from MyExpr.dfl.client_test import ClientTEST\n",
    "\n",
    "# train\n",
    "b_symmetric = args.b_symmetric\n",
    "topology_neighbors_num_undirected = args.topology_neighbors_num_undirected\n",
    "topology_neighbors_num_directed = args.topology_neighbors_num_directed\n",
    "input_dim = args.input_dim\n",
    "output_dim = 2\n",
    "\n",
    "iteration = int(train_sample_num_in_total / (client_number * args.batch_size))\n",
    "\n",
    "# print(train_sample_num_in_total / (client_number * args.batch_size))\n",
    "\n",
    "epoch = args.epoch_size\n",
    "\n",
    "if b_symmetric:\n",
    "    topology_manager = TopologyManager(client_number, True,\n",
    "                                       undirected_neighbor_num=topology_neighbors_num_undirected)\n",
    "else:\n",
    "    topology_manager = TopologyManager(client_number, False,\n",
    "                                       undirected_neighbor_num=topology_neighbors_num_undirected,\n",
    "                                       out_directed_neighbor=topology_neighbors_num_directed)\n",
    "topology_manager.generate_topology()\n",
    "print(\"finished topology generation\")\n",
    "\n",
    "client_list = []\n",
    "# todo 搞清楚latency\n",
    "for client_id in client_id_list:\n",
    "    model = LogisticRegression(input_dim, output_dim)\n",
    "    client_data = batch_data_dict[client_id]\n",
    "    client = ClientTEST(model, client_id, client_data, topology_manager, iteration, learning_rate=args.learning_rate, batch_size=args.batch_size, weight_decay=args.weight_decay, latency=args.latency, b_symmetric=b_symmetric)\n",
    "    client_list.append(client)\n",
    "print(\"finished client generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-44-80ff719c9ac9>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mclient\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mclient_list\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m             \u001B[0mtop_k\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtop_k_by_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclient_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m             \u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmutual_update\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtop_k\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m             \u001B[0mregret\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_regret\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m             \u001B[0mcorrect\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_record\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Fed_Expr/MyExpr/dfl/client_test.py\u001B[0m in \u001B[0;36mmutual_update\u001B[0;34m(self, top_k)\u001B[0m\n\u001B[1;32m    110\u001B[0m         \u001B[0mKL_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    111\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtop_k\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 112\u001B[0;31m             \u001B[0mKL_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mcriterion_KLD\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_softmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    113\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_softmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    114\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mKL_loss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36msoftmax\u001B[0;34m(input, dim, _stacklevel, dtype)\u001B[0m\n\u001B[1;32m   1678\u001B[0m         \u001B[0mdim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_softmax_dim\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"softmax\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_stacklevel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1679\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1680\u001B[0;31m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1681\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1682\u001B[0m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "test = True\n",
    "\n",
    "# 100(client_number)\n",
    "# 45(iteration) * 100(batch_size)\n",
    "# print(len(dataloader.BatchDataDict[1]['x'][0]))\n",
    "\n",
    "# check是不是每个都是相同的\n",
    "# for client in client_list:\n",
    "#     size = 100\n",
    "#     for i in range(len(client.streaming_data['x'])):\n",
    "#         if len(client.streaming_data['x'][i]) != size:\n",
    "#             print(client.id, i)\n",
    "\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # train\n",
    "    regret = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for t in range(iteration):\n",
    "        # logging.info('--- Iteration %d ---' % t)\n",
    "        # print('--- Iteration %d ---' % t)\n",
    "        # 本地训练 -> 广播\n",
    "        for client in client_list:\n",
    "            # print(type(client.streaming_data))\n",
    "            # print(len(client.streaming_data['x']))\n",
    "            # print(len(client.streaming_data['x'][t]), type(client.streaming_data['x'][t]), type(np.asarray(client.streaming_data['x'][t], dtype=np.float32)))\n",
    "            \n",
    "            client.train(t)\n",
    "            client.send_local_gradient_to_neighbor(client_list)\n",
    "\n",
    "        # Mutual Learning\n",
    "        for client in client_list:\n",
    "            top_k = client.top_k_by_loss(client_list, t)\n",
    "            client.mutual_update(top_k)\n",
    "            regret += client.get_regret()[t]\n",
    "            correct += client.get_record()[t][0]\n",
    "            total += client.get_record()[t][1]\n",
    "\n",
    "    print(client.loss_in_each_iteration)\n",
    "    print(\"epoch:\", e, \"train_regret:\", regret, \"train_acc:\", float(correct / train_sample_num_in_total), \"epoch:\", e)\n",
    "\n",
    "    # test (如果说是用个性化模型，那应该不能用统一的test集去检验)\n",
    "    regret = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for client in client_list:\n",
    "            model = client.model\n",
    "            for i in range(len(test_X)):\n",
    "                x, y = torch.from_numpy(np.asarray(test_X[i], dtype=np.float32)).float(), torch.from_numpy(np.asarray(test_Y[i], dtype=np.float32))\n",
    "                outputs = model(x)\n",
    "                \n",
    "                loss = client.criterion(outputs.squeeze(), y)\n",
    "                pred = outputs.ge(0.5).float()\n",
    "                correct += (pred.squeeze(1) == y).sum().item()\n",
    "                regret += loss.detach().numpy()\n",
    "        print(\"epoch:\", e, \"test_regret:\", regret, \"test_acc:\", float(correct / (len(test_X) * len(client_list) * args.batch_size)))\n",
    "\n",
    "    if test:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}